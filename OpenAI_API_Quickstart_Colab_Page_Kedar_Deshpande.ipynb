{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpO+8OXciYlUWJLAOMDRNX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kedardes/GPT-Collab-Pages/blob/main/OpenAI_API_Quickstart_Colab_Page_Kedar_Deshpande.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setting up the environment**\n",
        "\n",
        "Imagine this page is tied to a computer that already has all the hardware,software, whatever you'll need so that you can focus on just writing the final code snippets.\n",
        "\n",
        "Each grey block below is a code block. Anything written in those blocks all runs when you click the play button. You'll soon see why the API key is in a separate block soon.\n",
        "\n",
        "Adding in the text blocks are optional and more for your own documentation. You can add/remove, update order anytime you want without affecting the functionality of the page.\n"
      ],
      "metadata": {
        "id": "FUbe912MiI0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's start by installing the OpenAI package**</br>\n",
        "This lets the invisible computer know you'd like to use this package for this page"
      ],
      "metadata": {
        "id": "eOtezVlt0Clf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kO1JpqYkdTWu",
        "outputId": "12f7b55a-ac95-43ba-9edd-18ad9ae213cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Then import the OpenAI libraries** </br>\n",
        "This tells the page where to look to find the functions we want to use below. Instead of searching the entire 'computer' this sends it to directly where the functionality lives."
      ],
      "metadata": {
        "id": "ftZvfSgG0Zw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "s7MNOLZ6nPpB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setup your API key**\n",
        "Explain getting one, setting it up, rotating"
      ],
      "metadata": {
        "id": "Dod_ihzD0rsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = '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'"
      ],
      "metadata": {
        "id": "yrD55ZesnDL9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setting ChatGPT's 'role'**\n",
        "This is where "
      ],
      "metadata": {
        "id": "ftW1fQGq0whV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are an assistant that speaks like Shakespeare.\"},\n",
        "]"
      ],
      "metadata": {
        "id": "HreBF8tfnX-b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **First Method**\n",
        "* Using OpenAI Python Package\n",
        "* Continuous while loop\n",
        "\n",
        "Copy/paste the portion in the grey box. Yes, it looks like the code got cut off. Hit the play button and you'll see user : and a text field. Add in your prompt and hit enter. </br>Continue as long as you want. Hit stop in the grey box when you are done and you'll see an 'error' similar to the one below the grey box here. Ignore. </br>Whenever you want to run again, just hit play."
      ],
      "metadata": {
        "id": "aDc-I1Hr0-zn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    message = input(\"User : \")\n",
        "    if message:\n",
        "        messages.append(\n",
        "            {\"role\": \"user\", \"content\": message},\n",
        "        )\n",
        "        chat = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\", messages=messages\n",
        "            \n",
        "        )\n",
        "    \n",
        "    reply = chat.choices[0].message.content\n",
        "    print(f\"ChatGPT: {reply}\")\n",
        "    messages.append({\"role\": \"assistant\", \"content\": reply})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "sIolDeGOnwut",
        "outputId": "f6ca41b7-b83c-442e-f39b-70e24756d741"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User : what code is used to write chatgpt\n",
            "ChatGPT: The OpenAI team used Python as the primary programming language to develop the GPT (Generative Pre-trained Transformer) language model, which powers the chatbot AI like this one. The team used PyTorch, which is a popular machine learning library in Python, to build the GPT model architecture. They trained the GPT model on massive amounts of textual data, using techniques such as unsupervised pre-training and fine-tuning on specific tasks like language generation and question-answering, to achieve the impressive capabilities of the GPT language model.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-23993358dd39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"User : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         messages.append(\n\u001b[1;32m      5\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Second Method**\n",
        "* Using POST requests\n",
        "* Using API Endpoint\n",
        "\n",
        "Copy/paste the portion in the grey box. Yes, it looks like the code got cut off. Hit the play button and you'll see user : and a text field. Add in your prompt and hit enter. </br>Continue as long as you want. Hit stop in the grey box when you are done and you'll see an 'error' similar to the one below the grey box here. Ignore. </br>Whenever you want to run again, just hit play.\n"
      ],
      "metadata": {
        "id": "FN5EfceHtUy6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Making the call**</br>\n",
        "Here you send the request"
      ],
      "metadata": {
        "id": "vDv3XLGJm4uV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "URL = \"https://api.openai.com/v1/chat/completions\"\n",
        "\n",
        "payload = {\n",
        "\"model\": \"gpt-3.5-turbo\",\n",
        "\"messages\": [{\"role\": \"user\", \"content\": f\"in 5 words, what causes tides?\"}], #This is where the question goes\n",
        "\"temperature\" : 1.0,\n",
        "\"top_p\":1.0,\n",
        "\"n\" : 1,\n",
        "\"stream\": False,\n",
        "\"presence_penalty\":0,\n",
        "\"frequency_penalty\":0,\n",
        "}\n",
        "\n",
        "headers = {\n",
        "\"Content-Type\": \"application/json\",\n",
        "\"Authorization\": f\"Bearer {openai.api_key}\"\n",
        "}\n",
        "\n",
        "response = requests.post(URL, headers=headers, json=payload, stream=False)"
      ],
      "metadata": {
        "id": "YKnOS1rvsTcZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "View JSON Response"
      ],
      "metadata": {
        "id": "aA_U2PcP1aqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reading the response**</br>\n",
        "The response is JSON formatted"
      ],
      "metadata": {
        "id": "ubiBQmZknKO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "Pg_8JP2c1KqM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_response = json.loads(response.content)\n",
        "print(parsed_response[\"choices\"][0]['message']['content'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QemiA_Q2ufgN",
        "outputId": "4af9c336-2f10-4c63-a808-6b341ca89714"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Gravitational pull of celestial bodies.\n"
          ]
        }
      ]
    }
  ]
}